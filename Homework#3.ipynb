{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 3  \n",
    "Assignment Group 12  \n",
    "Ke Xu  \n",
    "Fangzhou Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are using pyspellchecker to do the test.  \n",
    "To install pyspellchecker:  \n",
    "pip install pyspellchecker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auxiliary\n",
      "address\n",
      "acres\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(['aadresa','auxillary','adres'])\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this spell checker, it has good dictionary so it has less unknow words. And it can deal with the word which has edit distance 3. Any other suggestions like using N-gram model and improve the error model(like change 'adres' to 'address') doesn't implement in this spell checker.In my opinion, his suggestions are really difficult to implement, I can't find a spell cheker is able to implement two of his suggestions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comedy: 0.5\n",
      "action: 0.5\n",
      "we cant decide which class this review should belong to.\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n",
    "import re\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "comedy = [ 'fun', 'couple', 'love', 'love', 'couple', 'fly', 'fast', 'fun', 'fun' ]\n",
    "action = [ 'fast', 'furious','shoot', 'furious', 'shoot', 'shoot', 'fun', 'fly', 'fast', 'shoot', 'love' ]\n",
    "\n",
    " \n",
    "comedy_features= [(word_feats(com), 'com') for com in comedy]\n",
    "action_features = [(word_feats(act), 'act') for act in action]\n",
    " \n",
    "train_set = comedy_features + action_features\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(train_set) \n",
    "\n",
    "# Predict\n",
    "com = 0\n",
    "act = 0\n",
    "s = \"fast, couple, shoot, fly\"\n",
    "s = s.lower()\n",
    "s = re.sub(r'[^\\w\\s]','',s)\n",
    "words = s.split(' ')\n",
    "for word in words:\n",
    "    classResult = classifier.classify( word_feats(word))\n",
    "    if classResult == 'com':\n",
    "        com = com + 1\n",
    "    if classResult == 'act':\n",
    "        act = act + 1\n",
    " \n",
    "print('comedy: ' + str(float(com)/len(words)))\n",
    "print('action: ' + str(float(act)/len(words)))\n",
    "print('we cant decide which class this review should belong to.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of this program: we divide the training data in two part, comedy and action. Then we mark every word in comedy class with 'com' and mark every word in action class with 'act, and build a classifier. Next, we input our test data, compare every word between test data and classifier. If any word more likely in comedy class then count 1 for comedy class, and if any word more likely in action class then count 1 in action class. Finally, we compute the probability of each class, find which class has highest probability, then set this review to that class. That how it works.  \n",
    "Back to problem 2, our test review is \"fast, couple, shoot, fly\" this cause both comedy and action class count 2, so we can't decide which class this review should belong to.  \n",
    "SentiWordNet is a lexical resource in which each WordNet synset is associated to three numerical scores Obj(s), Pos(s) and Neg(s), describing how objective, positive, and negative the terms contained in the synset are. Then input a review, we compare every word between the WordNet and review, and find how many postive, negative and objective words. And then compute the probablity of each of them. Then find the highest probablity, and set this review to that class(positive, negative, objective). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multinomial Naive Bayes:\n",
      "['pos']\n",
      "Binarized naive Bayes:\n",
      "['neg']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re\n",
    "\n",
    "# data for multinomial Naive Bayes count frequency for the words [good, poor, great]\n",
    "X = np.array([[3,0,3],[0,1,2],[1,3,0],[1,5,2],[0,2,0]])\n",
    "\n",
    "# data for Binarized naive Bayes only count occurrence [good, poor, great]\n",
    "X_bin = np.array([[1,0,1],[0,1,1],[1,1,0],[1,1,1],[0,1,0]])\n",
    "\n",
    "y= np.array(['pos','pos','neg','neg','neg'])\n",
    "clf = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "clf2 = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "clf.fit(X, y)\n",
    "clf2.fit(X_bin, y)\n",
    "\n",
    "#predict\n",
    "s =\"A good, good plot and great characters but poor acting.\"\n",
    "s = re.sub(r'[^\\w\\s]','',s)\n",
    "s = s.lower()\n",
    "good = 0\n",
    "poor = 0\n",
    "great = 0\n",
    "words = s.split(' ')\n",
    "for i in words:\n",
    "    if i == 'good':\n",
    "        good = good +1\n",
    "    if i == 'poor':\n",
    "        poor = poor +1\n",
    "    if i == 'great':\n",
    "        great = great +1\n",
    "test = np.array([[good, poor, great]])\n",
    "\n",
    "# test set for Binarized naive Bayes\n",
    "if good > 0: \n",
    "    good1 = 1\n",
    "else:\n",
    "    good1 = good\n",
    "if poor > 0: \n",
    "    poor1 = 1\n",
    "else:\n",
    "    poor1 = poor\n",
    "if great > 0: \n",
    "    great1 = 1\n",
    "else:\n",
    "    great1 = great\n",
    "test1 = np.array([[good1, poor1, great1]])\n",
    "print('The multinomial Naive Bayes:')\n",
    "print(clf.predict(test))\n",
    "print('Binarized naive Bayes:')\n",
    "print(clf2.predict(test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use both multionomial naive bayes and binarized naive bayes to do this problem. And we found the results are different. For the nultionomial naive bayes the result is positive but the binarized naive bayes the result is negative.  \n",
    "For multionomial naive bayes, this model is depend on frequency. Since our test review has 2 'good', 1 'poor' and 1 'great', this model will more likely to set this review to positive class depend on our training data.  \n",
    "For binarized naive bayes, it only count occurrence, frequency doesn't affect this model. From our training set, we found that when 'poor' appears in a review then this review will be negative. And the test set has 1 poor. Thus, the model set this test review to negative class.  \n",
    "That is the reason why we got two different results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
